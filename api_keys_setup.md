# API Keys Setup Guide This guide explains how to set up API keys for enhanced LLM-based sentiment analysis using OpenAI GPT and Anthropic Claude models. ## **API Key Configuration** ### **1. OpenAI API Setup (Optional)** **Get API Key:** 1. Visit https://platform.openai.com/api-keys 2. Create account or sign in 3. Click "Create new secret key" 4. Copy your API key (starts with `sk-`) **Set Environment Variable:** ```bash # Windows set OPENAI_API_KEY=sk-your-key-here # Linux/Mac export OPENAI_API_KEY=sk-your-key-here # Or add to .env file: echo "OPENAI_API_KEY=sk-your-key-here" >> .env ``` ### **2. Anthropic API Setup (Optional)** **Get API Key:** 1. Visit https://console.anthropic.com/ 2. Create account or sign in 3. Go to "API Keys" section 4. Click "Create Key" 5. Copy your API key (starts with `sk-ant-`) **Set Environment Variable:** ```bash # Windows set ANTHROPIC_API_KEY=sk-ant-your-key-here # Linux/Mac export ANTHROPIC_API_KEY=sk-ant-your-key-here # Or add to .env file: echo "ANTHROPIC_API_KEY=sk-ant-your-key-here" >> .env ``` ### **3. Install Required Libraries** ```bash # For OpenAI pip install openai # For Anthropic pip install anthropic # Both (recommended) pip install openai anthropic ``` ## [LAUNCH] **Usage Examples** ### **Example 1: Use Both APIs (Maximum Performance)** ```python from src.llm_sentiment_analyzer import LLMSentimentAnalyzer # Use both OpenAI and Anthropic for maximum accuracy analyzer = LLMSentimentAnalyzer( use_openai=True, # Uses GPT models use_anthropic=True, # Uses Claude models use_local_llm=True, # Also use local models fallback_to_finbert=True, # Fallback to FinBERT openai_model="gpt-4o-mini", # Cost-effective GPT model anthropic_model="claude-3-haiku-20240307" # Fast Claude model ) headlines = ["Fed raises rates to combat inflation"] results = analyzer.analyze_sentiment_batch(headlines) ``` ### **Example 2: OpenAI Only** ```python analyzer = LLMSentimentAnalyzer( use_openai=True, use_anthropic=False, use_local_llm=False, fallback_to_finbert=True, openai_model="gpt-3.5-turbo" # Cost-effective option ) ``` ### **Example 3: Anthropic Only** ```python analyzer = LLMSentimentAnalyzer( use_openai=False, use_anthropic=True, use_local_llm=False, fallback_to_finbert=True, anthropic_model="claude-3-haiku-20240307" # Fast and cost-effective ) ``` ### **Example 4: No API Keys (Free Fallback)** ```python # Works without any API keys - uses local models + FinBERT analyzer = LLMSentimentAnalyzer( use_openai=False, use_anthropic=False, use_local_llm=True, # Use local transformer models fallback_to_finbert=True # Always works with existing setup ) ``` ## [MONEY] **Cost Information** ### **OpenAI Pricing (as of 2024):** - **GPT-3.5-turbo**: ~$0.0015/1K tokens (very affordable) - **GPT-4o-mini**: ~$0.00015/1K tokens (cheapest GPT-4 class) - **GPT-4**: ~$0.03/1K tokens (premium) ### **Anthropic Pricing (as of 2024):** - **Claude 3 Haiku**: ~$0.00025/1K tokens (very affordable) - **Claude 3 Sonnet**: ~$0.003/1K tokens (balanced) - **Claude 3 Opus**: ~$0.015/1K tokens (premium) ### **Estimated Costs:** For typical usage (100 headlines/day): - **GPT-3.5-turbo**: ~$0.05/day - **Claude 3 Haiku**: ~$0.01/day - **Both combined**: ~$0.06/day (~$2/month) ## [TOOL] **Model Recommendations** ### **Cost-Effective Setup:** ```python # Best balance of performance and cost analyzer = LLMSentimentAnalyzer( use_openai=True, use_anthropic=True, openai_model="gpt-4o-mini", # $0.00015/1K tokens anthropic_model="claude-3-haiku-20240307", # $0.00025/1K tokens fallback_to_finbert=True ) ``` ### **Premium Performance Setup:** ```python # Maximum accuracy (higher cost) analyzer = LLMSentimentAnalyzer( use_openai=True, use_anthropic=True, openai_model="gpt-4", # Premium OpenAI anthropic_model="claude-3-opus-20240229", # Premium Anthropic fallback_to_finbert=True ) ``` ### **Free Tier Only:** ```python # No API costs - still gets enhanced capabilities analyzer = LLMSentimentAnalyzer( use_openai=False, use_anthropic=False, use_local_llm=True, # Local transformer models fallback_to_finbert=True # Existing FinBERT ) ``` ## **Environment File (.env)** Create a `.env` file in your project root: ```bash # OpenAI Configuration OPENAI_API_KEY=sk-your-openai-key-here # Anthropic Configuration ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here # Other existing keys GDELT_METHOD=free GOOGLE_CLOUD_PROJECT=your-project # ... other existing variables ``` ## [TEST] **Testing Your Setup** Run the test to verify your API keys: ```bash cd "macro_sentiment_trading" python src/llm_sentiment_analyzer.py ``` Expected output: ``` [TEST 1] Testing with API keys (if available)... INFO:llm_sentiment_analyzer:OpenAI client initialized successfully INFO:llm_sentiment_analyzer:Anthropic client initialized successfully API Configuration: {'openai_client_ready': True, 'anthropic_client_ready': True, ...} Testing API-based analysis... API Result: {'negative': 0.15, 'neutral': 0.25, 'positive': 0.60, 'polarity': 0.45} ``` ## **Security Best Practices** 1. **Never commit API keys** to version control 2. **Use environment variables** or `.env` files 3. **Add `.env` to `.gitignore`** 4. **Set usage limits** in API dashboards 5. **Monitor costs** regularly ## **Troubleshooting** ### **"API key not found" Error:** - Check environment variable spelling - Restart terminal/IDE after setting variables - Verify `.env` file is in project root ### **"Library not installed" Error:** ```bash pip install openai anthropic ``` ### **High API Costs:** - Use cheaper models (gpt-4o-mini, claude-3-haiku) - Reduce batch sizes - Increase caching - Set usage limits in API dashboards ## [TARGET] **Ready to Use** The system **automatically handles fallbacks**: 1. **API models first** (if keys available) 2. **Local models second** (if enabled) 3. **FinBERT fallback** (always available) **You can start with no API keys and add them later for enhanced performance!**