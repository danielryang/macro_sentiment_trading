{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Macro Sentiment Trading Pipeline\n",
    "\n",
    "This notebook provides an interactive interface to run the macro sentiment trading pipeline. You can:\n",
    "1. Run the complete pipeline\n",
    "2. Run individual components\n",
    "3. Visualize results at each stage\n",
    "4. Experiment with different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "from src.news_collector import GDELTCollector\n",
    "from src.headline_processor import HeadlineProcessor\n",
    "from src.sentiment_analyzer import SentimentAnalyzer\n",
    "from src.market_processor import MarketProcessor\n",
    "from src.model_trainer import ModelTrainer\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Collection and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_and_process_news(start_date: str, end_date: str, force_refresh: bool = False):\n",
    "    \"\"\"Collect and process news data.\"\"\"\n",
    "    collector = GDELTCollector()\n",
    "    processor = HeadlineProcessor()\n",
    "    \n",
    "    # Collect news\n",
    "    events_df = collector.fetch_events(start_date, end_date, force_refresh)\n",
    "    \n",
    "    # Process headlines\n",
    "    events_df = processor.process_articles(events_df)\n",
    "    \n",
    "    return events_df\n",
    "\n",
    "# Example usage\n",
    "start_date = \"2015-02-18\"\n",
    "end_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Uncomment to run\n",
    "# events_df = collect_and_process_news(start_date, end_date)\n",
    "# events_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(events_df: pd.DataFrame):\n",
    "    \"\"\"Analyze sentiment of headlines.\"\"\"\n",
    "    analyzer = SentimentAnalyzer()\n",
    "    \n",
    "    # Compute sentiment scores\n",
    "    sentiment_df = analyzer.compute_sentiment(events_df['headline'].tolist())\n",
    "    sentiment_df['date'] = events_df['date']\n",
    "    \n",
    "    # Compute daily features\n",
    "    daily_features = analyzer.compute_daily_features(sentiment_df)\n",
    "    \n",
    "    return sentiment_df, daily_features\n",
    "\n",
    "# Example usage\n",
    "# sentiment_df, daily_features = analyze_sentiment(events_df)\n",
    "# daily_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Market Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_market_data(start_date: str, end_date: str, daily_features: pd.DataFrame):\n",
    "    \"\"\"Process market data and align with sentiment features.\"\"\"\n",
    "    processor = MarketProcessor()\n",
    "    \n",
    "    # Fetch market data\n",
    "    market_data = processor.fetch_market_data(start_date, end_date)\n",
    "    \n",
    "    # Add market features\n",
    "    for asset_name in market_data:\n",
    "        market_data[asset_name] = processor.compute_market_features(\n",
    "            market_data[asset_name]\n",
    "        )\n",
    "    \n",
    "    # Align features\n",
    "    aligned_data = processor.align_features(market_data, daily_features)\n",
    "    \n",
    "    return aligned_data\n",
    "\n",
    "# Example usage\n",
    "# aligned_data = process_market_data(start_date, end_date, daily_features)\n",
    "# aligned_data['EURUSD'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training and Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_backtest(aligned_data: dict):\n",
    "    \"\"\"Train models and run backtest.\"\"\"\n",
    "    trainer = ModelTrainer()\n",
    "    results = {}\n",
    "    metrics = {}\n",
    "    \n",
    "    for asset_name, data in aligned_data.items():\n",
    "        # Set transaction costs\n",
    "        transaction_cost = 0.0002 if asset_name in ['EURUSD', 'USDJPY'] else 0.0005\n",
    "        \n",
    "        # Run backtest\n",
    "        asset_results = trainer.backtest(data, transaction_cost)\n",
    "        results[asset_name] = asset_results\n",
    "        \n",
    "        # Compute metrics\n",
    "        asset_metrics = {}\n",
    "        for model_name, model_results in asset_results.items():\n",
    "            asset_metrics[model_name] = trainer.compute_metrics(\n",
    "                model_results['returns']\n",
    "            )\n",
    "        metrics[asset_name] = asset_metrics\n",
    "        \n",
    "        # Generate SHAP values\n",
    "        if 'xgboost' in asset_results:\n",
    "            shap_values = trainer.explain_predictions(\n",
    "                trainer.models['xgboost'],\n",
    "                data\n",
    "            )\n",
    "            \n",
    "    return results, metrics\n",
    "\n",
    "# Example usage\n",
    "# results, metrics = train_and_backtest(aligned_data)\n",
    "# pd.DataFrame(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Complete Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_complete_pipeline(start_date: str, end_date: str, force_refresh: bool = False):\n",
    "    \"\"\"Run the complete pipeline.\"\"\"\n",
    "    # Step 1: Collect and process news\n",
    "    print(\"Step 1: Collecting and processing news...\")\n",
    "    events_df = collect_and_process_news(start_date, end_date, force_refresh)\n",
    "    \n",
    "    # Step 2: Analyze sentiment\n",
    "    print(\"\\nStep 2: Analyzing sentiment...\")\n",
    "    sentiment_df, daily_features = analyze_sentiment(events_df)\n",
    "    \n",
    "    # Step 3: Process market data\n",
    "    print(\"\\nStep 3: Processing market data...\")\n",
    "    aligned_data = process_market_data(start_date, end_date, daily_features)\n",
    "    \n",
    "    # Step 4: Train models and backtest\n",
    "    print(\"\\nStep 4: Training models and running backtest...\")\n",
    "    results, metrics = train_and_backtest(aligned_data)\n",
    "    \n",
    "    return {\n",
    "        'events_df': events_df,\n",
    "        'sentiment_df': sentiment_df,\n",
    "        'daily_features': daily_features,\n",
    "        'aligned_data': aligned_data,\n",
    "        'results': results,\n",
    "        'metrics': metrics\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "# pipeline_results = run_complete_pipeline(start_date, end_date)\n",
    "# pipeline_results['metrics']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sentiment_trends(daily_features: pd.DataFrame):\n",
    "    \"\"\"Plot sentiment trends over time.\"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.plot(daily_features.index, daily_features['sentiment_score'])\n",
    "    plt.title('Daily Sentiment Score')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Sentiment Score')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_returns(results: dict, asset_name: str):\n",
    "    \"\"\"Plot cumulative returns for an asset.\"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for model_name, model_results in results[asset_name].items():\n",
    "        cum_returns = (1 + model_results['returns']).cumprod()\n",
    "        plt.plot(cum_returns.index, cum_returns, label=model_name)\n",
    "    plt.title(f'Cumulative Returns - {asset_name}')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Cumulative Return')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_shap_values(shap_values: pd.DataFrame, top_n: int = 10):\n",
    "    \"\"\"Plot SHAP value importance.\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    shap_values.abs().mean().sort_values(ascending=True).tail(top_n).plot(kind='barh')\n",
    "    plt.title('Feature Importance (SHAP Values)')\n",
    "    plt.xlabel('Mean |SHAP value|')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "# plot_sentiment_trends(daily_features)\n",
    "# plot_returns(results, 'EURUSD')\n",
    "# plot_shap_values(shap_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
