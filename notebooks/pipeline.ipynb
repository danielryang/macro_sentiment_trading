{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Macro Sentiment Trading Pipeline\n",
    "\n",
    "This notebook provides an interactive interface to run the macro sentiment trading pipeline. You can:\n",
    "1. Run the complete pipeline\n",
    "2. Run individual components\n",
    "3. Visualize results at each stage\n",
    "4. Experiment with different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\Users\\danie\\Coding Projects\\Personal\\macro_sentiment_trading\n",
      "Python path: ['C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\\\python311.zip', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\\\DLLs', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\\\Lib', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0', 'c:\\\\Users\\\\danie\\\\Coding Projects\\\\Personal\\\\macro_sentiment_trading\\\\.venv', '', 'c:\\\\Users\\\\danie\\\\Coding Projects\\\\Personal\\\\macro_sentiment_trading\\\\.venv\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\danie\\\\Coding Projects\\\\Personal\\\\macro_sentiment_trading\\\\.venv\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\danie\\\\Coding Projects\\\\Personal\\\\macro_sentiment_trading\\\\.venv\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\danie\\\\Coding Projects\\\\Personal\\\\macro_sentiment_trading\\\\.venv\\\\Lib\\\\site-packages\\\\Pythonwin', 'c:\\\\Users\\\\danie\\\\Coding Projects\\\\Personal\\\\macro_sentiment_trading']\n",
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\Coding Projects\\Personal\\macro_sentiment_trading\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Set up paths\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root directory to Python path\n",
    "project_root = os.path.abspath(os.path.join(os.path.dirname('__file__'), '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# Verify the path is correct\n",
    "print(\"Project root:\", project_root)\n",
    "print(\"Python path:\", sys.path)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "from src.news_collector import GDELTCollector\n",
    "from src.headline_processor import HeadlineProcessor\n",
    "from src.sentiment_analyzer import SentimentAnalyzer\n",
    "from src.market_processor import MarketProcessor\n",
    "from src.model_trainer import ModelTrainer\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs('data/news', exist_ok=True)\n",
    "os.makedirs('data/raw/gdelt', exist_ok=True)\n",
    "os.makedirs('results', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Collection and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[32m     15\u001b[39m start_date = \u001b[33m\"\u001b[39m\u001b[33m2015-02-18\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m end_date = \u001b[43mdatetime\u001b[49m.now().strftime(\u001b[33m\"\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Uncomment to run\u001b[39;00m\n\u001b[32m     19\u001b[39m events_df = collect_and_process_news(start_date, end_date)\n",
      "\u001b[31mNameError\u001b[39m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "def collect_and_process_news(start_date: str, end_date: str, force_refresh: bool = False):\n",
    "    \"\"\"Collect and process news data.\"\"\"\n",
    "    collector = GDELTCollector()\n",
    "    processor = HeadlineProcessor()\n",
    "    \n",
    "    # Collect news\n",
    "    events_df = collector.fetch_events(start_date, end_date, force_refresh)\n",
    "    \n",
    "    # Process headlines\n",
    "    events_df = processor.process_articles(events_df)\n",
    "    \n",
    "    return events_df\n",
    "\n",
    "# Example usage\n",
    "start_date = \"2015-02-18\"\n",
    "end_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Uncomment to run\n",
    "events_df = collect_and_process_news(start_date, end_date)\n",
    "events_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(events_df: pd.DataFrame):\n",
    "    \"\"\"Analyze sentiment of headlines.\"\"\"\n",
    "    analyzer = SentimentAnalyzer()\n",
    "    \n",
    "    # Compute sentiment scores\n",
    "    sentiment_df = analyzer.compute_sentiment(events_df['headline'].tolist())\n",
    "    sentiment_df['date'] = events_df['date']\n",
    "    \n",
    "    # Compute daily features\n",
    "    daily_features = analyzer.compute_daily_features(sentiment_df)\n",
    "    \n",
    "    return sentiment_df, daily_features\n",
    "\n",
    "# Example usage\n",
    "# sentiment_df, daily_features = analyze_sentiment(events_df)\n",
    "# daily_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Market Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_market_data(start_date: str, end_date: str, daily_features: pd.DataFrame):\n",
    "    \"\"\"Process market data and align with sentiment features.\"\"\"\n",
    "    processor = MarketProcessor()\n",
    "    \n",
    "    # Fetch market data\n",
    "    market_data = processor.fetch_market_data(start_date, end_date)\n",
    "    \n",
    "    # Add market features\n",
    "    for asset_name in market_data:\n",
    "        market_data[asset_name] = processor.compute_market_features(\n",
    "            market_data[asset_name]\n",
    "        )\n",
    "    \n",
    "    # Align features\n",
    "    aligned_data = processor.align_features(market_data, daily_features)\n",
    "    \n",
    "    return aligned_data\n",
    "\n",
    "# Example usage\n",
    "# aligned_data = process_market_data(start_date, end_date, daily_features)\n",
    "# aligned_data['EURUSD'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training and Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_backtest(aligned_data: dict):\n",
    "    \"\"\"Train models and run backtest.\"\"\"\n",
    "    trainer = ModelTrainer()\n",
    "    results = {}\n",
    "    metrics = {}\n",
    "    \n",
    "    for asset_name, data in aligned_data.items():\n",
    "        # Set transaction costs\n",
    "        transaction_cost = 0.0002 if asset_name in ['EURUSD', 'USDJPY'] else 0.0005\n",
    "        \n",
    "        # Run backtest\n",
    "        asset_results = trainer.backtest(data, transaction_cost)\n",
    "        results[asset_name] = asset_results\n",
    "        \n",
    "        # Compute metrics\n",
    "        asset_metrics = {}\n",
    "        for model_name, model_results in asset_results.items():\n",
    "            asset_metrics[model_name] = trainer.compute_metrics(\n",
    "                model_results['returns']\n",
    "            )\n",
    "        metrics[asset_name] = asset_metrics\n",
    "        \n",
    "        # Generate SHAP values\n",
    "        if 'xgboost' in asset_results:\n",
    "            shap_values = trainer.explain_predictions(\n",
    "                trainer.models['xgboost'],\n",
    "                data\n",
    "            )\n",
    "            \n",
    "    return results, metrics\n",
    "\n",
    "# Example usage\n",
    "# results, metrics = train_and_backtest(aligned_data)\n",
    "# pd.DataFrame(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Complete Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_complete_pipeline(start_date: str, end_date: str, force_refresh: bool = False):\n",
    "    \"\"\"Run the complete pipeline.\"\"\"\n",
    "    # Step 1: Collect and process news\n",
    "    print(\"Step 1: Collecting and processing news...\")\n",
    "    events_df = collect_and_process_news(start_date, end_date, force_refresh)\n",
    "    \n",
    "    # Step 2: Analyze sentiment\n",
    "    print(\"\\nStep 2: Analyzing sentiment...\")\n",
    "    sentiment_df, daily_features = analyze_sentiment(events_df)\n",
    "    \n",
    "    # Step 3: Process market data\n",
    "    print(\"\\nStep 3: Processing market data...\")\n",
    "    aligned_data = process_market_data(start_date, end_date, daily_features)\n",
    "    \n",
    "    # Step 4: Train models and backtest\n",
    "    print(\"\\nStep 4: Training models and running backtest...\")\n",
    "    results, metrics = train_and_backtest(aligned_data)\n",
    "    \n",
    "    return {\n",
    "        'events_df': events_df,\n",
    "        'sentiment_df': sentiment_df,\n",
    "        'daily_features': daily_features,\n",
    "        'aligned_data': aligned_data,\n",
    "        'results': results,\n",
    "        'metrics': metrics\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "# pipeline_results = run_complete_pipeline(start_date, end_date)\n",
    "# pipeline_results['metrics']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sentiment_trends(daily_features: pd.DataFrame):\n",
    "    \"\"\"Plot sentiment trends over time.\"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.plot(daily_features.index, daily_features['sentiment_score'])\n",
    "    plt.title('Daily Sentiment Score')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Sentiment Score')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_returns(results: dict, asset_name: str):\n",
    "    \"\"\"Plot cumulative returns for an asset.\"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for model_name, model_results in results[asset_name].items():\n",
    "        cum_returns = (1 + model_results['returns']).cumprod()\n",
    "        plt.plot(cum_returns.index, cum_returns, label=model_name)\n",
    "    plt.title(f'Cumulative Returns - {asset_name}')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Cumulative Return')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_shap_values(shap_values: pd.DataFrame, top_n: int = 10):\n",
    "    \"\"\"Plot SHAP value importance.\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    shap_values.abs().mean().sort_values(ascending=True).tail(top_n).plot(kind='barh')\n",
    "    plt.title('Feature Importance (SHAP Values)')\n",
    "    plt.xlabel('Mean |SHAP value|')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "# plot_sentiment_trends(daily_features)\n",
    "# plot_returns(results, 'EURUSD')\n",
    "# plot_shap_values(shap_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
